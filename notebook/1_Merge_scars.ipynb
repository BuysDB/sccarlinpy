{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import sys\n",
    "from io import StringIO\n",
    "from sccarlinpy.align import  BiasedScoringMatrix, LocalAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the target reference sequence and primer:\n",
    "primer_seq = 'CGGATTAACGTGTAAGCGGC'\n",
    "region_offset=2861\n",
    "ref = \"gcttctgctcggattaaCgtgtaagcggcGCTAGCcgccggactgcacgacagtcgacgatggagtcgacacgactcgcgcatacgatggagtcgactacagtcgctacgacgatggagtcgcgagcgctatgagcgactatggagtcgatacgatacgcgcacgctatggagtcgagagcgcgctcgtcgactatggagtcgcgactgtacgcacacgcgatggagtcgatagtatgcgtacacgcgatggagtcgagtcgagacgctgacgatatggagtcgatacgtagcacgcagacgatgggagctagaattctaactagagctcgctgatcagccCCCGGGtcgactgtgccttctagttgccagccatctgttgtttgcccctcccccgtgccttccttgaccctggaaggtgccactcccactgtcctttcctaataaaatgaggaaattgcatcgcattgtctgagtaggtgtcattctattctggggggtggggtggggcaggacagcaagggggaggattgggaagagaatagcaggcatgctggggaAGATCTtaagctgcaataaacaagttaacaacaacaattgcatt\".upper()\n",
    "ref_name = 'Tigre_d2egfp_carlin_2e12_1f11'\n",
    "###\n",
    "\n",
    "\n",
    "primer_offset = ref.index(primer_seq)\n",
    "scoring = BiasedScoringMatrix(20, -15, biased_reference_positions=set(list(range(primer_offset,primer_offset+len(primer_seq)+1))), \n",
    "                              biased_match_score= 80, \n",
    "                              biased_query_positions=set(list(range(0,len(primer_seq)+1))))\n",
    "sw = LocalAlignment(scoring, full_query=True, prefer_gap_runs=True, gap_penalty=-50, gap_extension_penalty=-1 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from multiprocessing import Pool\n",
    "from collections import defaultdict, Counter\n",
    "from sccarlinpy import add_to_readset\n",
    "\n",
    "longreadset = Counter()\n",
    "shortreadset = Counter()\n",
    "\n",
    "sequences_per_cell = defaultdict(lambda: defaultdict(Counter)) # library -> cell -> reads [n]\n",
    "\n",
    "\n",
    "for path in glob.glob('../data/long/*.scstats.tsv'):\n",
    "    add_to_readset(path, longreadset, sequences_per_cell)    \n",
    "\n",
    "for path in glob.glob('../data/short/*.scstats.tsv'):\n",
    "    add_to_readset(path, shortreadset, sequences_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68880it [03:15, 352.69it/s] \n",
      "316610it [10:15, 514.31it/s] \n"
     ]
    }
   ],
   "source": [
    "# Perform alignments\n",
    "from sccarlinpy import get_alignment\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _get_alignment(read):\n",
    "    # Requires globals : ref, sw and ref_name\n",
    "    return get_alignment(read, ref, sw, ref_name)\n",
    "\n",
    "aln_chunksize = 100\n",
    "mincount = 2\n",
    "\n",
    "read_alignments_long = {}\n",
    "with Pool() as workers:\n",
    "    for read, alignment in tqdm(workers.imap(_get_alignment, \n",
    "                                        (read for read,count in longreadset.items() if count>=mincount), chunksize=aln_chunksize)\n",
    "                               ):\n",
    "        read_alignments_long[read] = alignment\n",
    "    \n",
    "read_alignments_short = {}\n",
    "with Pool() as workers:\n",
    "    for read, alignment in tqdm(workers.imap(_get_alignment, (read for read,count in shortreadset.items() if count>=mincount), chunksize=aln_chunksize)):\n",
    "        read_alignments_short[read] = alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316000 316610  \r"
     ]
    }
   ],
   "source": [
    "from singlecellmultiomics.utils import hamming_distance\n",
    "\n",
    "safe_short_to_longer = dict() \n",
    "unsafe_short_to_longer = dict()\n",
    "short_missing_in_longer = set()\n",
    "\n",
    "def read_to_safe_unsafe(args):\n",
    "    short_read, short_alignment = args\n",
    "    unsafe = set()\n",
    "    safe = set()\n",
    "    is_safe = True\n",
    "    for longer_read, long_alignment in read_alignments_long.items():\n",
    "        prefix = longer_read[:len(short_read)]\n",
    "        d = hamming_distance(prefix, short_read)\n",
    "        if d<=1:\n",
    "            if long_alignment==short_alignment:\n",
    "                safe.add(longer_read)\n",
    "                # The longer read has the same alignment as the shorter read, likely no ambiguity\n",
    "            else:\n",
    "                unsafe.add(longer_read)\n",
    "                is_safe = False # There are multiple long read alignments which fit this shorter read\n",
    "    return short_read, safe, unsafe, is_safe\n",
    "\n",
    "\n",
    "\n",
    "with Pool() as workers:\n",
    "    for i, (shortread, safe, unsafe, is_safe) in enumerate(workers.imap_unordered(read_to_safe_unsafe, read_alignments_short.items(), chunksize=100)):\n",
    "        if i%1000==0:\n",
    "            print(f'{i} {len(read_alignments_short)}  ',  end='\\r')\n",
    "        if is_safe and len(safe)>0:\n",
    "            safe_short_to_longer[shortread] = safe\n",
    "        elif not is_safe:\n",
    "            unsafe_short_to_longer[shortread] = unsafe.union(safe)\n",
    "        else:\n",
    "            short_missing_in_longer.add(shortread) # This sequence is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of short sequences: 316610\n",
      "Number of long sequences: 68880\n",
      "\n",
      "Number of short sequences safely convertable to long: 114591\n",
      "Number of short sequences which are ambigous convertable to long: 43775\n",
      "Number of short sequences which are not found in the long read set: 158244\n"
     ]
    }
   ],
   "source": [
    "print('Number of short sequences:', len(read_alignments_short))\n",
    "print('Number of long sequences:', len(read_alignments_long))\n",
    "print()\n",
    "print('Number of short sequences safely convertable to long:', len(safe_short_to_longer))\n",
    "print('Number of short sequences which are ambigous convertable to long:', len(unsafe_short_to_longer))\n",
    "print('Number of short sequences which are not found in the long read set:', len(short_missing_in_longer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_header = \"\"\"@SQ\tSN:1\tLN:195154279\n",
    "@SQ\tSN:10\tLN:130530862\n",
    "@SQ\tSN:11\tLN:121973369\n",
    "@SQ\tSN:12\tLN:120092757\n",
    "@SQ\tSN:13\tLN:120883175\n",
    "@SQ\tSN:14\tLN:125139656\n",
    "@SQ\tSN:15\tLN:104073951\n",
    "@SQ\tSN:16\tLN:98008968\n",
    "@SQ\tSN:17\tLN:95294699\n",
    "@SQ\tSN:18\tLN:90720763\n",
    "@SQ\tSN:19\tLN:61420004\n",
    "@SQ\tSN:2\tLN:181755017\n",
    "@SQ\tSN:3\tLN:159745316\n",
    "@SQ\tSN:4\tLN:156860686\n",
    "@SQ\tSN:5\tLN:151758149\n",
    "@SQ\tSN:6\tLN:149588044\n",
    "@SQ\tSN:7\tLN:144995196\n",
    "@SQ\tSN:8\tLN:130127694\n",
    "@SQ\tSN:9\tLN:124359700\n",
    "@SQ\tSN:MT\tLN:16299\n",
    "@SQ\tSN:X\tLN:169476592\n",
    "@SQ\tSN:Y\tLN:91455967\n",
    "@SQ\tSN:JH584299.1\tLN:953012\n",
    "@SQ\tSN:GL456233.2\tLN:559103\n",
    "@SQ\tSN:JH584301.1\tLN:259875\n",
    "@SQ\tSN:GL456211.1\tLN:241735\n",
    "@SQ\tSN:GL456221.1\tLN:206961\n",
    "@SQ\tSN:JH584297.1\tLN:205776\n",
    "@SQ\tSN:JH584296.1\tLN:199368\n",
    "@SQ\tSN:GL456354.1\tLN:195993\n",
    "@SQ\tSN:JH584298.1\tLN:184189\n",
    "@SQ\tSN:JH584300.1\tLN:182347\n",
    "@SQ\tSN:GL456219.1\tLN:175968\n",
    "@SQ\tSN:GL456210.1\tLN:169725\n",
    "@SQ\tSN:JH584303.1\tLN:158099\n",
    "@SQ\tSN:JH584302.1\tLN:155838\n",
    "@SQ\tSN:GL456212.1\tLN:153618\n",
    "@SQ\tSN:JH584304.1\tLN:114452\n",
    "@SQ\tSN:GL456379.1\tLN:72385\n",
    "@SQ\tSN:GL456366.1\tLN:47073\n",
    "@SQ\tSN:GL456367.1\tLN:42057\n",
    "@SQ\tSN:GL456239.1\tLN:40056\n",
    "@SQ\tSN:GL456383.1\tLN:38659\n",
    "@SQ\tSN:GL456385.1\tLN:35240\n",
    "@SQ\tSN:GL456360.1\tLN:31704\n",
    "@SQ\tSN:GL456378.1\tLN:31602\n",
    "@SQ\tSN:MU069435.1\tLN:31129\n",
    "@SQ\tSN:GL456389.1\tLN:28772\n",
    "@SQ\tSN:GL456372.1\tLN:28664\n",
    "@SQ\tSN:GL456370.1\tLN:26764\n",
    "@SQ\tSN:GL456381.1\tLN:25871\n",
    "@SQ\tSN:GL456387.1\tLN:24685\n",
    "@SQ\tSN:GL456390.1\tLN:24668\n",
    "@SQ\tSN:GL456394.1\tLN:24323\n",
    "@SQ\tSN:GL456392.1\tLN:23629\n",
    "@SQ\tSN:GL456382.1\tLN:23158\n",
    "@SQ\tSN:GL456359.1\tLN:22974\n",
    "@SQ\tSN:GL456396.1\tLN:21240\n",
    "@SQ\tSN:GL456368.1\tLN:20208\n",
    "@SQ\tSN:MU069434.1\tLN:8412\n",
    "@SQ\tSN:JH584295.1\tLN:1976\n",
    "@SQ\tSN:Tigre_d2egfp_carlin_2e12_1f11\tLN:5346\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day7b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81376ac0fd5343a5a9796f2a2bc566cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cdf8fc45af497eb7e636ca56cad509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day5c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba5f60f373c4373b726fd51f6125f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276889 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day5b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0586d5b00d464e36aed8a56cd2cafc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/281622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day7c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11b45716e1e44d5bcedcbee351dd97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day7a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f28cf19989b4eeeb1c14789ff6e0ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day5a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123e85d1c4824f4ca7b5c1ca54fac49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/241220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc35610f987d4be28b91df671164344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write all data (long form):\n",
    "import gzip\n",
    "from singlecellmultiomics.utils import pool_wrapper\n",
    "from tqdm.notebook import tqdm\n",
    "import os \n",
    "alignment_commands = {}\n",
    "\n",
    "def alignment_wrapper(query_name, query_sequence, cell, scar ):\n",
    "    # Depends on region_offet, ref,\n",
    "    aln = sw.align(ref, query_sequence, query_name=query_name, ref_name=ref_name, q_qual=None)\n",
    "    q_name, flag, r_name,  start, mapq, cigar, _, __, tlen, seq, q_qual = aln.dump_sam(region_offset)\n",
    "    q_qual = 'A' * len(seq)                    \n",
    "    return '\\t'.join([str(x) for x in [q_name, flag, r_name,  start, mapq, cigar, _, __, tlen, seq, q_qual, f'SC:Z:{scar}', f'SM:Z:{cell}']])+ '\\n'\n",
    "\n",
    "def align_sequences_to_sam(sam_out_path, commands):\n",
    "    with open(sam_out_path,'w') as samout:\n",
    "        samout.write(sam_header)\n",
    "        with Pool() as workers:\n",
    "            for sam_line in tqdm( workers.imap(pool_wrapper, ( (alignment_wrapper, kwargs) for kwargs in commands)), total=len(commands) ):\n",
    "                samout.write( sam_line )                   \n",
    "    bam_path = sam_out_path.replace('.sam', '.bam')\n",
    "    os.system(f\"samtools sort {sam_out_path} -o {bam_path} --write-index \")\n",
    "\n",
    "with gzip.open('../data/all_scar_data_wttagged.tsv.gz','wt') as h:\n",
    "    for library, cell_data in sequences_per_cell.items():\n",
    "        print(library)\n",
    "        sam_out_path = f'../data/{library}.sam'\n",
    "        alignment_commands = []\n",
    "   \n",
    "        for cell, observed_sequences in cell_data.items():\n",
    "            wrote_cell = False\n",
    "                \n",
    "            for seq_index, (sequence, n) in enumerate(observed_sequences.most_common()):\n",
    "                if n<2: # Too little observations\n",
    "                    continue\n",
    "                if not wrote_cell:\n",
    "                    h.write(f'CELL\\t{cell}\\n')\n",
    "                    wrote_cell = True\n",
    "                if sequence in read_alignments_long:\n",
    "                    scar = ''.join([f'{n}{op}'  for n, op in read_alignments_long[sequence]])\n",
    "                    is_safe = True\n",
    "                    is_long = True\n",
    "                elif sequence in safe_short_to_longer:\n",
    "                    scar = ''.join([f'{n}{op}' for n, op in read_alignments_short[sequence]])\n",
    "                    is_safe = True\n",
    "                    is_long = False\n",
    "                else:\n",
    "                    is_long=False\n",
    "                    if sequence in read_alignments_short:\n",
    "                        scar = ''.join([f'{n}{op}' for n, op in read_alignments_short[sequence]])\n",
    "                    else:\n",
    "                        scar = 'undefined'\n",
    "                    is_safe = False\n",
    "                \n",
    "                h.write(f'\\t{n}\\t{\"Safe\" if is_safe else \"Amb\"}\\t{\"Long\" if is_long else \"Short\"}\\t{scar}\\t{sequence}\\n')\n",
    "                # Write to the sam file:\n",
    "\n",
    "                alignment_commands.append( { # query_name, query_sequence, cell, scar \n",
    "                    'query_name': f\"{cell}_{seq_index}\",\n",
    "                    \"query_sequence\": sequence,\n",
    "                    \"cell\":cell,\n",
    "                    \"scar\":scar\n",
    "                })\n",
    "        \n",
    "        ### Perform the alignments\n",
    "        align_sequences_to_sam(sam_out_path, alignment_commands)\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
